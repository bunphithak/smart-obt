#!/usr/bin/env node

/**
 * Migration Runner Script
 * Run database migrations automatically
 */

const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');
require('dotenv').config();

// Database connection (à¹ƒà¸Šà¹‰à¸„à¹ˆà¸² default à¹€à¸«à¸¡à¸·à¸­à¸™ lib/db.js)
const pool = new Pool({
  host: process.env.DB_HOST || 'localhost',
  port: parseInt(process.env.DB_PORT) || 5432,
  user: process.env.DB_USER || 'bunphithak',
  password: process.env.DB_PASSWORD || '',
  database: process.env.DB_NAME || 'smart_obt',
});

// Migration files to run
const migrations = [
  '001_update_status_constraints.sql',
  '002_add_missing_columns.sql',
  '003_convert_status_to_english_keys.sql',
  '004_update_problem_type_to_uuid.sql',
  '005_add_category_to_reports.sql',
  '006_add_village_to_reports.sql',
];

async function runMigrations() {
  console.log('ðŸš€ Starting database migrations...\n');
  console.log(`ðŸ“Š Database: ${process.env.DB_NAME || 'smart_obt'}`);
  console.log(`ðŸ‘¤ User: ${process.env.DB_USER || 'bunphithak'}`);
  console.log(`ðŸ–¥ï¸  Host: ${process.env.DB_HOST || 'localhost'}:${process.env.DB_PORT || 5432}\n`);

  try {
    // Test connection
    await pool.query('SELECT NOW()');
    console.log('âœ… Database connection successful\n');

    for (const migrationFile of migrations) {
      console.log(`ðŸ“„ Running migration: ${migrationFile}`);
      
      const migrationPath = path.join(__dirname, '..', 'database', 'migrations', migrationFile);
      
      if (!fs.existsSync(migrationPath)) {
        console.log(`âš ï¸  Migration file not found: ${migrationFile}\n`);
        continue;
      }

      const sql = fs.readFileSync(migrationPath, 'utf8');
      
      try {
        await pool.query(sql);
        console.log(`âœ… Migration completed: ${migrationFile}\n`);
      } catch (error) {
        console.error(`âŒ Migration failed: ${migrationFile}`);
        console.error(`Error: ${error.message}\n`);
        
        // Continue with other migrations even if one fails
        continue;
      }
    }

    // Verify assets table structure
    console.log('ðŸ” Verifying assets table structure...');
    const result = await pool.query(`
      SELECT column_name, data_type, is_nullable
      FROM information_schema.columns 
      WHERE table_name = 'assets' 
      ORDER BY ordinal_position
    `);

    console.log('\nðŸ“‹ Assets table columns:');
    console.table(result.rows.map(row => ({
      'Column': row.column_name,
      'Type': row.data_type,
      'Nullable': row.is_nullable
    })));

    console.log('\nâœ… All migrations completed successfully!');
    
  } catch (error) {
    console.error('\nâŒ Migration process failed:', error.message);
    
    // Check if it's a database not found error
    if (error.message.includes('does not exist')) {
      const dbName = process.env.DB_NAME || 'smart_obt';
      const dbUser = process.env.DB_USER || 'bunphithak';
      
      console.log('\nðŸ’¡ à¸§à¸´à¸˜à¸µà¹à¸à¹‰à¹„à¸‚:');
      console.log('\n1. à¹€à¸‚à¹‰à¸² PostgreSQL:');
      console.log(`   psql -U ${dbUser} -d postgres`);
      console.log('\n2. à¸ªà¸£à¹‰à¸²à¸‡ database:');
      console.log(`   CREATE DATABASE ${dbName};`);
      console.log('\n3. à¸­à¸­à¸à¸ˆà¸²à¸ psql:');
      console.log('   \\q');
      console.log('\n4. Run migration à¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡:');
      console.log('   npm run migrate');
      console.log('\n---à¸«à¸£à¸·à¸­---');
      console.log('\nà¹ƒà¸Šà¹‰à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¹€à¸”à¸µà¸¢à¸§:');
      console.log(`createdb -U ${dbUser} ${dbName}`);
      console.log('\nà¹à¸¥à¹‰à¸§ run: npm run migrate\n');
    }
    
    process.exit(1);
  } finally {
    await pool.end();
  }
}

// Run migrations
runMigrations().catch(error => {
  console.error('Fatal error:', error);
  process.exit(1);
});


